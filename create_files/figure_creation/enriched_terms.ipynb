{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath('../')\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import data_dir \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"{parent_dir}data_enrichr2.json\", \"r\") as c:\n",
    "    enrichr = json.load(c)\n",
    "df = pd.DataFrame(list([(name, stuff[\"enrich view\"][0][0], stuff[\"enrich view\"][1][0], stuff[\"enrich view\"][2][0]) for name, stuff in enrichr.items()]\n",
    "), columns=[\"Name\", \"Enrichr View Link\", \"Enrichr RummaGEO Link\", \"Enrichr Rummagene Link\"])\n",
    "\n",
    "df[[\"rummagene\", \"rummageo\"]] =df[\"Name\"].str.split(\";\", expand=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.read_csv(f\"{parent_dir}/rummagenexrummageo.csv\")\n",
    "df = df.head(1000000)\n",
    "df = pd.merge(df, dfe, on=[\"rummagene\", \"rummageo\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def get_enrichr_terms(tup):\n",
    "    ENRICHR_URL = 'https://maayanlab.cloud/Enrichr/'\n",
    "    ele = tup.split(\"?\")[1]\n",
    "    user_list_id = ele.split(\"=\")[1]\n",
    "    enrichr_libraries = ['WikiPathway_2023_Human', 'GWAS_Catalog_2023', 'GO_Biological_Process_2023', 'MGI_Mammalian_Phenotype_Level_4_2024']\n",
    "    enriched_terms = {}\n",
    "    enrichr_stats = {}    \n",
    "    for enrichr_library in enrichr_libraries:\n",
    "        query_string = f'enrich?userListId={user_list_id}&backgroundType={enrichr_library}'\n",
    "        try:\n",
    "            response = requests.get(ENRICHR_URL + query_string, headers={'Accept': 'application/json'})\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            enriched_terms[enrichr_library] = []\n",
    "            for term in data[enrichr_library][:3]:  # Limit to top 3 results\n",
    "                term_name = term[1]\n",
    "                enriched_terms[enrichr_library].append(f\"{term_name} ({enrichr_library})\")\n",
    "                enrichr_stats[term_name] = term\n",
    "                enrichr_stats[term_name].append(enrichr_library)\n",
    "            time.sleep(2)  # Delay between requests\n",
    "\n",
    "        except requests.exceptions.RequestException as error:\n",
    "            print(f\"Error: {error}\")\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return enriched_terms, enrichr_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = []\n",
    "stats = []\n",
    "indices = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index not in indices:\n",
    "        enrichment_overlap= get_enrichr_terms(row[\"Enrichr View Link\"])\n",
    "        enrichment_geo= get_enrichr_terms(row[\"Enrichr RummaGEO Link\"])\n",
    "\n",
    "        enrichment_gene= get_enrichr_terms(row[\"Enrichr Rummagene Link\"])\n",
    "\n",
    "\n",
    "        if enrichment_overlap and enrichment_geo and enrichment_gene:\n",
    "            terms, stats = enrichment_overlap\n",
    "            termseo, statseo = enrichment_geo\n",
    "            termsgene, statsgene = enrichment_gene\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                \"GeneSet\": row[\"Name\"],\n",
    "                \"Overlap Terms\": \";\".join([item for sublist in terms.values() for item in sublist]),\n",
    "                \"Rummagene Terms\": \";\".join([item for sublist in termseo.values() for item in sublist]),\n",
    "                \"RummaGEO Terms\": \";\".join([item for sublist in termsgene.values() for item in sublist]),\n",
    "\n",
    "            })\n",
    "            indices.append(index)\n",
    "        time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"data/enriched_terms_overall.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split strings by ';' and flatten the list\n",
    "all_phrases = [phrase for row in results_df[\"Overlap Terms\"] for phrase in row.split(\";\")]\n",
    "all_phraseseo = [phrase for row in results_df[\"RummaGEO Terms\"] for phrase in row.split(\";\")]\n",
    "all_phrasesgene = [phrase for row in results_df[\"Rummagene Terms\"] for phrase in row.split(\";\")]\n",
    "\n",
    "\n",
    "# Count the frequencies\n",
    "phrase_counts = Counter(all_phrases)\n",
    "phrase_countseo = Counter(all_phraseseo)\n",
    "phrase_countsgene = Counter(all_phrasesgene)\n",
    "\n",
    "\n",
    "# Get the 10 most common phrases\n",
    "most_common_phrases = phrase_counts.most_common(10)\n",
    "most_common_phraseseo = phrase_countseo.most_common(10)\n",
    "most_common_phrasesgene = phrase_countsgene.most_common(10)\n",
    "\n",
    "\n",
    "# Prepare data for plotting\n",
    "phrases, counts = zip(*most_common_phrases)\n",
    "\n",
    "# Create the horizontal bar chart\n",
    "plt.figure(figsize=(6, 10))\n",
    "plt.barh(phrases, counts, color=\"black\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "# plt.ylabel(\"Phrases\")\n",
    "plt.title(\"Most Common Enriched Terms in the top 1000 Hypotheses\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
