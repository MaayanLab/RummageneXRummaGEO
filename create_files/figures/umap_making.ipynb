{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "from common import data_dir, GMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/rummagenexrummageo.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common import data_dir, cached_urlretrieve, maybe_tqdm\n",
    "\n",
    "(data_dir/'Enrichr').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cached_urlretrieve(\n",
    "  'https://maayanlab.cloud/Enrichr/datasetStatistics',\n",
    "  data_dir/'Enrichr'/'datasetStatistics.json'\n",
    ")\n",
    "with (data_dir/'Enrichr'/'datasetStatistics.json').open('r') as fr:\n",
    "  datasetStatistics = json.load(fr)\n",
    "datasetStatistics\n",
    "\n",
    "for library in maybe_tqdm(datasetStatistics['statistics'], desc='Downloading Enrichr database...'):\n",
    "  cached_urlretrieve(\n",
    "    f\"https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName={library['libraryName']}\",\n",
    "    data_dir/'Enrichr'/(library['libraryName']+'.gmt')\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import data_dir, GMT, maybe_tqdm\n",
    "\n",
    "\n",
    "with (data_dir/'enrichr.gmt').open('w') as fw:\n",
    "  for gene_set_library in maybe_tqdm((data_dir/'Enrichr').glob('*.gmt'), desc='Processing enrichr libraries...'):\n",
    "    for (term, _desc), genes in maybe_tqdm(GMT.reader(gene_set_library), desc=f\"Processing {gene_set_library}...\"):\n",
    "      print(\n",
    "        gene_set_library.stem,\n",
    "        term,\n",
    "        *genes,\n",
    "        sep='\\t',\n",
    "        file=fw,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from common import data_dir, cached_urlretrieve, maybe_tqdm\n",
    "\n",
    "organism = 'Mammalia/Homo_sapiens'\n",
    "\n",
    "def maybe_split(record):\n",
    "  ''' NCBI Stores Nulls as '-' and lists '|' delimited\n",
    "  '''\n",
    "  if record in {'', '-'}:\n",
    "    return set()\n",
    "  return set(record.split('|'))\n",
    "\n",
    "def supplement_dbXref_prefix_omitted(ids):\n",
    "  ''' NCBI Stores external IDS with Foreign:ID while most datasets just use the ID\n",
    "  '''\n",
    "  for id in ids:\n",
    "    # add original id\n",
    "    yield id\n",
    "    # also add id *without* prefix\n",
    "    if ':' in id:\n",
    "      yield id.split(':', maxsplit=1)[1]\n",
    "\n",
    "cached_urlretrieve(\n",
    "  f\"ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/{organism}.gene_info.gz\",\n",
    "  data_dir/f\"{organism}.gene_info.gz\"\n",
    ")\n",
    "ncbi_genes = pd.read_csv(data_dir/f\"{organism}.gene_info.gz\", sep='\\t', compression='gzip')\n",
    "ncbi_genes['All_synonyms'] = [\n",
    "  set.union(\n",
    "    maybe_split(gene_info['Symbol']),\n",
    "    maybe_split(gene_info['Symbol_from_nomenclature_authority']),\n",
    "    maybe_split(str(gene_info['GeneID'])),\n",
    "    maybe_split(gene_info['Synonyms']),\n",
    "    maybe_split(gene_info['Other_designations']),\n",
    "    maybe_split(gene_info['LocusTag']),\n",
    "    set(supplement_dbXref_prefix_omitted(maybe_split(gene_info['dbXrefs']))),\n",
    "  )\n",
    "  for _, gene_info in maybe_tqdm(ncbi_genes.iterrows())\n",
    "]\n",
    "synonyms, symbols = zip(*{\n",
    "  (synonym, gene_info['Symbol'])\n",
    "  for _, gene_info in maybe_tqdm(ncbi_genes.iterrows())\n",
    "  for synonym in gene_info['All_synonyms']\n",
    "})\n",
    "ncbi_lookup = pd.Series(symbols, index=synonyms)\n",
    "index_values = ncbi_lookup.index.value_counts()\n",
    "ambiguous = index_values[index_values > 1].index\n",
    "ncbi_lookup_disambiguated = ncbi_lookup[(\n",
    "  (ncbi_lookup.index == ncbi_lookup) | (~ncbi_lookup.index.isin(ambiguous))\n",
    ")]\n",
    "ncbi_lookup = ncbi_lookup_disambiguated.to_dict()\n",
    "\n",
    "with (data_dir / 'lookup.json').open('w') as fw:\n",
    "  json.dump(ncbi_lookup, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from common import GMT, maybe_tqdm, gene_lookup\n",
    "\n",
    "input_file = './data/enrichr.gmt'\n",
    "output_file = 'data/enrichr-clean.gmt'\n",
    "\n",
    "# Open the input and output files\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for (term, desc), genes in maybe_tqdm(GMT.reader(infile), desc='Cleaning gmt...'):\n",
    "        # Map genes to their canonical forms\n",
    "        genes_mapped = {\n",
    "            gene_mapped\n",
    "            for gene in genes\n",
    "            for gene_mapped in (gene_lookup(gene),)\n",
    "            if gene_mapped\n",
    "        }\n",
    "        # Skip gene sets with fewer than 5 mapped genes\n",
    "        if len(genes_mapped) < 5:\n",
    "            continue\n",
    "        \n",
    "        # Write the cleaned term, description, and genes to the output file\n",
    "        outfile.write(f\"{term}\\t{desc}\\t\" + \"\\t\".join(genes_mapped) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def csv_to_gmt(df):\n",
    "    batch_file = \"data/rummageogene_500k.gmt\"\n",
    "    dfe = df.sort_values(by=[\"p-value\", \"odds\"], ascending=[True, False])\n",
    "    dfe = dfe.head(500000)\n",
    "    dfe.to_csv(\"data/rummageogene_top_500k.csv\", index=False)\n",
    "    with open(batch_file, 'w') as gmtfile:\n",
    "        for index, row in dfe.iterrows():\n",
    "            identifier = row[\"rummagene\"] + \";\" + row[\"rummageo\"]\n",
    "            desc = \"N/A\"\n",
    "            # Combine the row elements with tabs\n",
    "            genes = row[\"overlaps\"].split(\";\")\n",
    "            gmt_row = [identifier, desc] + genes\n",
    "            gmtfile.write('\\t'.join(gmt_row) + '\\n')\n",
    "\n",
    "csv_to_gmt(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Enrichr GMT...')\n",
    "enrichr_gmt = GMT.from_file(data_dir/'enrichr-clean.gmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Rummageogene GMT...')\n",
    "rummageogene_gmt = GMT.from_file('data/rummageogene_500k.gmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Collecting metadata...')\n",
    "meta = pd.DataFrame(\n",
    "  [\n",
    "    { 'source': library, 'term': term }\n",
    "    for library, term in enrichr_gmt.terms\n",
    "  ] + [\n",
    "    { 'source': 'rummagenexrummageo', 'term': term }\n",
    "    for term, desc in rummageogene_gmt.terms\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing IDF...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda gs: gs)\n",
    "vectors = vectorizer.fit_transform(enrichr_gmt.gene_lists + rummageogene_gmt.gene_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing SVD...')\n",
    "svd = TruncatedSVD(n_components=50, random_state=random_state)\n",
    "svs = svd.fit_transform(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing UMAP...')\n",
    "umap = UMAP(random_state=random_state, low_memory=True)\n",
    "embedding = umap.fit_transform(svs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing outliers...')\n",
    "x = embedding[:, 0]\n",
    "y = embedding[:, 1]\n",
    "x_min, x_mu, x_std, x_max = np.min(x), np.mean(x), np.std(x), np.max(x)\n",
    "x_lo, x_hi = max(x_min, x_mu - x_std*1.68), min(x_max, x_mu + x_std*1.68)\n",
    "y_min, y_mu, y_std, y_max = np.min(y), np.mean(y), np.std(y), np.max(y)\n",
    "y_lo, y_hi = max(y_min, y_mu - y_std*1.68), min(y_max, y_mu + y_std*1.68)\n",
    "outlier = (x>=x_lo)&(x<=x_hi)&(y>=y_lo)&(y<=y_hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving joint-umap...')\n",
    "meta['UMAP-1'] = x\n",
    "meta['UMAP-2'] = y\n",
    "meta['outlier'] = (~outlier).astype(int)\n",
    "meta.to_csv(data_dir / 'joint-umap.tsv', sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(data_dir / 'joint-umap.tsv', sep='\\t')\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing Cluster UMAP...')\n",
    "cluster_umap = UMAP(\n",
    "  n_neighbors=30,\n",
    "  min_dist=0.0,\n",
    "  n_components=2,\n",
    "  random_state=random_state,\n",
    "  low_memory=True,\n",
    ")\n",
    "cluster_embedding = cluster_umap.fit_transform(svs)\n",
    "\n",
    "print('Computing Clusters...')\n",
    "labels = HDBSCAN(\n",
    "    min_samples=10,\n",
    "    min_cluster_size=500,\n",
    ").fit_predict(cluster_embedding)\n",
    "\n",
    "x = cluster_embedding[:, 0]\n",
    "y = cluster_embedding[:, 1]\n",
    "meta['UMAP-1'] = x\n",
    "meta['UMAP-2'] = y\n",
    "meta['cluster'] = labels\n",
    "meta.to_csv(data_dir / 'joint-umap-cluster.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glasbey\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from common import data_dir\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "fig_dir = pathlib.Path('figures')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.concat([\n",
    "  pd.read_csv(data_dir / 'joint-umap.tsv', sep='\\t', index_col=0),\n",
    "  pd.read_csv(data_dir / 'joint-umap-cluster.tsv', sep='\\t', index_col=1)[['cluster']],\n",
    "], axis=1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/rummageogene_top_500k.csv\", usecols=[\"rummagene\", \"rummageo\", \"species\"])\n",
    "df[\"term\"] = df[\"rummagene\"] + \";\" + df[\"rummageo\"]\n",
    "df = df[[\"term\", \"species\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.reset_index()\n",
    "merged_df = pd.merge(meta, df, on='term', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df['source'] = merged_df.apply(\n",
    "    lambda row: f\"{row['source']}-{row['species']}\" if pd.notna(row['species']) else row['source'],\n",
    "    axis=1\n",
    ")\n",
    "meta = merged_df.drop(columns='species')\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (data_dir/'Enrichr'/'datasetStatistics.json').open('r') as fr:\n",
    "  datasetStatistics = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {cat['categoryId']: cat['name'] for cat in datasetStatistics['categories']}\n",
    "library_categories = {lib['libraryName']: categories[lib['categoryId']] for lib in datasetStatistics['statistics']}\n",
    "library_categories['rummagenexrummageo'] = 'RummagenexRummaGEO'\n",
    "library_categories['rummagenexrummageo-human'] = 'RummageneXhumanRummaGEO'\n",
    "library_categories['rummagenexrummageo-mouse'] = 'RummageneXmouseRummaGEO'\n",
    "\n",
    "\n",
    "meta['category'] = meta['source'].apply(library_categories.get)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "_ = meta[(meta['category'] != 'RummageneXhumanRummaGEO') & (meta['category'] != 'RummageneXmouseRummaGEO')]\n",
    "\n",
    "cat = 'category'\n",
    "cats = _[cat].unique()\n",
    "color_pallete = dict(zip(cats, glasbey.create_palette(len(cats))))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), dpi=300)  # 1 row, 2 columns\n",
    "\n",
    "for label, data in _.groupby(cat):\n",
    "    ax1.scatter(\n",
    "        x=data['UMAP-1'],\n",
    "        y=data['UMAP-2'],\n",
    "        s=0.1,  \n",
    "        color=color_pallete[label],\n",
    "        alpha=0.1,\n",
    "        rasterized=True,\n",
    "    )\n",
    "ax1.set_xlabel('UMAP-1', fontdict=dict(size=24))\n",
    "ax1.set_ylabel('UMAP-2', fontdict=dict(size=24))\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Enrichr Only', fontsize=24)\n",
    "\n",
    "_ = meta\n",
    "cat = 'category'\n",
    "cats = _[cat].unique()\n",
    "color_pallete = dict(zip(cats, glasbey.create_palette(len(cats))))\n",
    "\n",
    "for label, data in _.groupby(cat):\n",
    "    ax2.scatter(\n",
    "        x=data['UMAP-1'],\n",
    "        y=data['UMAP-2'],\n",
    "        s=0.1,  \n",
    "        color=color_pallete[label],\n",
    "        alpha=0.1,\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "lgd = ax2.legend(handles=[\n",
    "    Line2D([0], [0], marker='o', color='w', label=f\"{label} ({int((_[cat] == label).sum()):,})\",\n",
    "           markerfacecolor=color_pallete[label], markersize=10)\n",
    "    for label in cats\n",
    "], loc='center left', bbox_to_anchor=(1, 0.5), fontsize=16)\n",
    "\n",
    "ax2.set_xlabel('UMAP-1', fontdict=dict(size=24))\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Enrichr + RummagenexRummaGEO', fontsize=24)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{fig_dir}/enrichr_rummageogene_combined.png\", dpi=300)\n",
    "plt.savefig(f\"{fig_dir}/enrichr_rummageogene_combined.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"color\"] = meta['category'].apply(color_pallete.get)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8), dpi=300)\n",
    "\n",
    "for label, data in _.groupby(cat):\n",
    "    ax2.scatter(\n",
    "        x=data['UMAP-1'],\n",
    "        y=data['UMAP-2'],\n",
    "        s=0.1,  \n",
    "        color=color_pallete[label],\n",
    "        alpha=0.1,\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "for label, data in _.groupby(cat):\n",
    "    plt.scatter(\n",
    "        x=data['UMAP-1'],\n",
    "        y=data['UMAP-2'],\n",
    "        s=0.1, \n",
    "        color=color_pallete[label],\n",
    "        alpha=0.1,\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "plt.legend(handles=[\n",
    "    Line2D([0], [0], marker='o', color='w', label=f\"{label} ({int((_[cat] == label).sum()):,})\",\n",
    "           markerfacecolor=color_pallete[label], markersize=8)\n",
    "    for label in cats\n",
    "], loc='center left', bbox_to_anchor=(1, 0.5), fontsize=12)\n",
    "\n",
    "plt.xlabel('UMAP-1', fontdict=dict(size=24))\n",
    "plt.ylabel('UMAP-2', fontdict=dict(size=24))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Enrichr + RummagenexRummaGEO', fontsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Filter for unique points (non-duplicated UMAP-1, UMAP-2 pairs)\n",
    "unique_data = _.loc[~_.duplicated(subset=['UMAP-1', 'UMAP-2'], keep=False)]\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(15, 8), dpi=300)\n",
    "\n",
    "# Scatter plot for unique points (non-overlapping)\n",
    "for label, data in unique_data.groupby(cat):\n",
    "    plt.scatter(\n",
    "        x=data['UMAP-1'],\n",
    "        y=data['UMAP-2'],\n",
    "        s=0.1,  \n",
    "        color=color_pallete[label],\n",
    "        alpha=0.8,  # Slightly higher alpha to make unique points more visible\n",
    "        rasterized=True,\n",
    "    )\n",
    "\n",
    "# Add legend\n",
    "plt.legend(handles=[\n",
    "    Line2D([0], [0], marker='o', color='w', label=f\"{label} ({int((unique_data[cat] == label).sum()):,})\",\n",
    "           markerfacecolor=color_pallete[label], markersize=8)\n",
    "    for label in cats\n",
    "], loc='center left', bbox_to_anchor=(1, 0.5), fontsize=12)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('UMAP-1', fontdict=dict(size=24))\n",
    "plt.ylabel('UMAP-2', fontdict=dict(size=24))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Enrichr + RummagenexRummaGEO', fontsize=24)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
