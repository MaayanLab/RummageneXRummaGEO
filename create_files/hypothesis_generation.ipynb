{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "df = pd.read_csv(\"./data/rummagenexrummageo.csv\")\n",
    "df = df.drop_duplicates(subset='pmc_id', keep='first')\n",
    "df = df.sort_values(by=[\"p-value\", \"odds\"], ascending=[True, False])\n",
    "df.index = np.arange(1, len(df)+1)\n",
    "df = df.head(1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rummagene_map = {row[\"rummagene\"]: [row[\"rummagene-desc\"], row[\"pmc_id\"]] for _, row in df.iterrows()}\n",
    "df_rummageo_map = {row[\"rummageo\"]: [row[\"geo_gse\"], row[\"geo_gsei\"], row[\"species\"]] for _, row in df.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/gse_results.json\" ,\"r\") as f:\n",
    "        gse_info = json.load(f)\n",
    "with open(\"../data/title_abs.json\" ,\"r\") as f:\n",
    "        pmc_sum = json.load(f)\n",
    "with open(\"../data/human-gse-processed-meta.json\") as f:\n",
    "        gse_human_info = json.load(f)\n",
    "with open(\"../data/mouse-gse-processed-meta.json\") as f:\n",
    "        gse_mouse_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_after_extension(termid):\n",
    "    pattern = r'^(.+?\\.\\w+)-+(.*)$'\n",
    "    \n",
    "    match = re.match(pattern, termid)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmc_again(pmcids):\n",
    "    pmc_dict = {}\n",
    "    for pm in pmcids:\n",
    "        pmc_dict[pm] = (pmc_sum[pmcids[pm][1]][\"title\"], pmc_sum[pmcids[pm][1]][\"abstract\"], extract_after_extension(pm), pmcids[pm][0])\n",
    "\n",
    "    return pmc_dict\n",
    "\n",
    "\n",
    "fin_pmc = pmc_again(df_rummagene_map)\n",
    "fin_pmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gse_again(gseids):\n",
    "    gse_dict = {}\n",
    "    for gse in gseids:\n",
    "        if gseids[gse][2] == \"human\":\n",
    "            dt = gse_human_info\n",
    "        else:\n",
    "            dt = gse_mouse_info\n",
    "        title = gse_info[gseids[gse][0]][\"title\"] \n",
    "        summary = gse_info[gseids[gse][0]][\"summary\"][0]\n",
    "        cond1= dt[gseids[gse][1]][\"titles\"][gse.split(\"-\")[1]] \n",
    "        cond2 = dt[gseids[gse][1]][\"titles\"][gse.split(\"-\")[3]]\n",
    "        dir = gse.split(\"-\")[4].split(\" \")[0]\n",
    "        gse_dict[gse] = (title, summary, cond1,cond2, dir)\n",
    "    return gse_dict\n",
    "\n",
    "fin_gse = gse_again(df_rummageo_map)\n",
    "fin_gse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def get_enrichr_terms(genes):\n",
    "    ENRICHR_URL = 'https://maayanlab.cloud/Enrichr/'\n",
    "    endpoint = 'addList'\n",
    "    user_list_id = None\n",
    "    enrichr_libraries = ['WikiPathway_2023_Human', 'GWAS_Catalog_2023', \n",
    "                         'GO_Biological_Process_2023', 'MGI_Mammalian_Phenotype_Level_4_2021']\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        gen = genes.split(\";\")\n",
    "        genes_string = '\\n'.join(gen).replace(\"'\", '')\n",
    "        response = requests.post(\n",
    "            ENRICHR_URL + endpoint,\n",
    "            files={'list': (None, genes_string), 'description': (None, '')}\n",
    "            # headers={'Content-Type': 'multipart/form-data'}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        user_list_id = data['userListId']\n",
    "    except requests.exceptions.RequestException as error:\n",
    "        print(f\"Error: {error}\")\n",
    "        return\n",
    "\n",
    "    enriched_terms = {}\n",
    "    enrichr_stats = {}\n",
    "\n",
    "    for enrichr_library in enrichr_libraries:\n",
    "        query_string = f'enrich?userListId={user_list_id}&backgroundType={enrichr_library}'\n",
    "        try:\n",
    "            response = requests.get(ENRICHR_URL + query_string, headers={'Accept': 'application/json'})\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            enriched_terms[enrichr_library] = []\n",
    "            for term in data[enrichr_library][:3]:  # Limit to top 3 results\n",
    "                term_name = term[1]\n",
    "                enriched_terms[enrichr_library].append(term_name)\n",
    "                enrichr_stats[term_name] = term\n",
    "                enrichr_stats[term_name].append(enrichr_library)\n",
    "\n",
    "            time.sleep(0.5)  # Delay between requests\n",
    "\n",
    "        except requests.exceptions.RequestException as error:\n",
    "            print(f\"Error: {error}\")\n",
    "            return\n",
    "\n",
    "    return enriched_terms, enrichr_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "def fetch_hypothesis(pm_title, user_desc: str, desct, desc, gse_title, gse_summary: str, cond1, cond2, species, term1: str,term2: str, enriched_terms: dict, enriched_stats: dict) -> str:\n",
    "    # Define the system prompt\n",
    "    system_prompt = (\n",
    "        \"You are an AI hypothesis generator for RummagenexRummaGEO (gene sets from crossing Rummagene sets with RummaGEO sets). \"\n",
    "        \"You should act as a biologist in hypothesizing why a high overlap may exist between a Rummagene set (which are sets from PubMed papers) and a RummaGEO set (automatically generated signatures from Gene Expression Omnibus).\"\n",
    "    )\n",
    "\n",
    "    # Build the enriched terms string\n",
    "    enriched_terms_string = \"\"\n",
    "    for library, terms in enriched_terms.items():\n",
    "        enriched_terms_string += f\"{library}: {', '.join(terms)}\\n\"\n",
    "\n",
    "    # Define the main prompt to be sent to the AI\n",
    "    prompt = (\n",
    "        f\"Here are two gene sets that highly overlap. The first is from a Rummagene set. \"\n",
    "        f\"The second is a gene set automatically computed between two conditions in a study from the Gene Expression Omnibus (GEO). \"\n",
    "        f\"Based upon the term name (formatted as condition 1 vs. condition 2) and the abstract of the GEO gene set, \"\n",
    "        f\"and the abstract of the Rummagene gene set, please hypothesize about why these two gene sets have a significant high overlap. \"\n",
    "        f\"You should mention both the summary of the RummaGEO gene set and the description of the Rummagene gene set in your hypothesis. \"\n",
    "        f\"You will also be provided with enrichment results from the Enrichr database to help you generate your hypothesis, which shows \"\n",
    "        f\"significantly overlapping functional terms from the overlapping genes of the two sets. \"\n",
    "        f\"For each enrichment term that appears in your response, the term should appear in the exact form it was given to you \"\n",
    "        f\"(do not exclude any words or characters from a term. For example, Complement And Coagulation Cascades WP558 should appear as \"\n",
    "        f\"Complement And Coagulation Cascades WP558, not Complement And Coagulation Cascades). Also, please don't use quotes around the enriched term names. \"\n",
    "        f\"Gene set term 1 from RummaGEO: {term2}\\n\"\n",
    "        f'\"up\" or \"dn\" in this{term2} name indicates if the genes were upregulated or downregulated in {cond1} vs {cond2} conditions in the signature for species {species}.Please make sure to include this detail in your hypothesis.\\n'\n",
    "        f\"title of study for gene set term 1: {gse_title}\\n\"\n",
    "        f\"summary of study for gene set term 1: {gse_summary}\\n\"\n",
    "        f\"Gene set term 2 from Rummagene: {term1}\\n\"\n",
    "        f\"title of paper for gene set term 2: {pm_title}\\n\"\n",
    "        f\"abstract of paper for gene set term 2: {user_desc}\\n\"\n",
    "        f\"{desct}is the name of the table from the paper which the gene set comes from and {desc} is its description. Please include this detail if relevant\\n\"\n",
    "        f\"Enriched Terms from overlapping genes of the two sets:\\n\"\n",
    "        f\"{enriched_terms_string}\"\n",
    "    )\n",
    "\n",
    "    # Send the request to the OpenAI API\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Parse the response from the API\n",
    "    response_json = response.json()\n",
    "    hypothesis = response_json['choices'][0]['message']['content']\n",
    "\n",
    "    # Replace enriched terms in the hypothesis with detailed text\n",
    "    for term, stats in enriched_stats.items():\n",
    "        if term in hypothesis:\n",
    "            details = (\n",
    "                f\"Term: {term}\\tLibrary: {stats[9]}\\tRank: {stats[0]}\\tP-value: {float(stats[2]):.2e}\\tOdds Ratio: {float(stats[3]):.4f}\\n\"\n",
    "            )\n",
    "            hypothesis = hypothesis.replace(term, f\"{term} ({details})\")\n",
    "\n",
    "    return hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jwt\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_hypothesis\u001b[39m(pm_title, user_desc: \u001b[38;5;28mstr\u001b[39m, desct, desc, gse_title, gse_summary: \u001b[38;5;28mstr\u001b[39m, cond1, cond2, species, term1: \u001b[38;5;28mstr\u001b[39m, term2: \u001b[38;5;28mstr\u001b[39m, enriched_terms: \u001b[38;5;28mdict\u001b[39m, enriched_stats: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Define the system prompt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from google.auth import jwt\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "def fetch_hypothesis(pm_title, user_desc: str, desct, desc, gse_title, gse_summary: str, cond1, cond2, species, term1: str, term2: str, enriched_terms: dict, enriched_stats: dict) -> str:\n",
    "    # Define the system prompt\n",
    "    system_prompt = (\n",
    "        \"You are an AI hypothesis generator for RummagenexRummaGEO (gene sets from crossing Rummagene sets with RummaGEO sets). \"\n",
    "        \"You should act as a biologist in hypothesizing why a high overlap may exist between a Rummagene set (which are sets from PubMed papers) and a RummaGEO set (automatically generated signatures from Gene Expression Omnibus).\"\n",
    "    )\n",
    "\n",
    "    # Build the enriched terms string\n",
    "    enriched_terms_string = \"\"\n",
    "    for library, terms in enriched_terms.items():\n",
    "        enriched_terms_string += f\"{library}: {', '.join(terms)}\\n\"\n",
    "\n",
    "    # Define the main prompt to be sent to the AI\n",
    "    prompt = (\n",
    "        f\"Here are two gene sets that highly overlap. The first is from a Rummagene set. \"\n",
    "        f\"The second is a gene set automatically computed between two conditions in a study from the Gene Expression Omnibus (GEO). \"\n",
    "        f\"Based upon the term name (formatted as condition 1 vs. condition 2) and the abstract of the GEO gene set, \"\n",
    "        f\"and the abstract of the Rummagene gene set, please hypothesize about why these two gene sets have a significant high overlap. \"\n",
    "        f\"You should mention both the summary of the RummaGEO gene set and the description of the Rummagene gene set in your hypothesis. \"\n",
    "        f\"You will also be provided with enrichment results from the Enrichr database to help you generate your hypothesis, which shows \"\n",
    "        f\"significantly overlapping functional terms from the overlapping genes of the two sets. \"\n",
    "        f\"For each enrichment term that appears in your response, the term should appear in the exact form it was given to you \"\n",
    "        f\"(do not exclude any words or characters from a term. For example, Complement And Coagulation Cascades WP558 should appear as \"\n",
    "        f\"Complement And Coagulation Cascades WP558, not Complement And Coagulation Cascades). Also, please don't use quotes around the enriched term names. \"\n",
    "        f\"Gene set term 1 from RummaGEO: {term2}\\n\"\n",
    "        f'\"up\" or \"dn\" in this{term2} name indicates if the genes were upregulated or downregulated in {cond1} vs {cond2} conditions in the signature for species {species}.Please make sure to include this detail in your hypothesis.\\n'\n",
    "        f\"title of study for gene set term 1: {gse_title}\\n\"\n",
    "        f\"summary of study for gene set term 1: {gse_summary}\\n\"\n",
    "        f\"Gene set term 2 from Rummagene: {term1}\\n\"\n",
    "        f\"title of paper for gene set term 2: {pm_title}\\n\"\n",
    "        f\"abstract of paper for gene set term 2: {user_desc}\\n\"\n",
    "        f\"{desct} is the name of the table from the paper which the gene set comes from and {desc} is its description. Please include this detail if relevant\\n\"\n",
    "        f\"Enriched Terms from overlapping genes of the two sets:\\n\"\n",
    "        f\"{enriched_terms_string}\"\n",
    "    )\n",
    "\n",
    "    # Authenticate with the Gemini API\n",
    "    credentials = jwt.Credentials.from_service_account_file(\n",
    "        \"path/to/service_account.json\",\n",
    "        audience=\"https://gemini.googleapis.com\",\n",
    "    )\n",
    "    auth_request = Request()\n",
    "    credentials.refresh(auth_request)\n",
    "    \n",
    "    # Send the request to the Gemini API\n",
    "    response = requests.post(\n",
    "        \"https://gemini.googleapis.com/v1/models/gemini-model/complete\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {credentials.token}\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"gemini-model\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Parse the response from the API\n",
    "    response_json = response.json()\n",
    "    hypothesis = response_json.get('choices', [{}])[0].get('message', {}).get('content', '')\n",
    "\n",
    "    # Replace enriched terms in the hypothesis with detailed text\n",
    "    for term, stats in enriched_stats.items():\n",
    "        if term in hypothesis:\n",
    "            details = (\n",
    "                f\"Term: {term}\\tLibrary: {stats[9]}\\tRank: {stats[0]}\\tP-value: {float(stats[2]):.2e}\\tOdds Ratio: {float(stats[3]):.4f}\\n\"\n",
    "            )\n",
    "            hypothesis = hypothesis.replace(term, f\"{term} ({details})\")\n",
    "\n",
    "    return hypothesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_list = list(zip(df[\"rummagene\"], df['rummageo'], df[\"overlaps\"]))\n",
    "hypotheses = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pmcid, geo_id, ov) in enumerate(tuples_list):\n",
    "        term = f\"{pmcid};{geo_id}\"\n",
    "        if term not in hypotheses: \n",
    "            try:\n",
    "                terms, stats = get_enrichr_terms(ov)\n",
    "                hypothesis = fetch_hypothesis(pm_title=fin_pmc[pmcid][0], user_desc=fin_pmc[pmcid][1], desct=fin_pmc[pmcid][2], desc=fin_pmc[pmcid][3], gse_title=fin_gse[geo_id][0],gse_summary=fin_gse[geo_id][1], cond1=fin_gse[geo_id][2], cond2=fin_gse[geo_id][3],species=fin_gse[geo_id][4], term1=pmcid, term2=geo_id, enriched_terms=terms, enriched_stats=stats)\n",
    "                hypotheses[term] = hypothesis\n",
    "                with open('data_hyp.json', 'w') as json_file:\n",
    "                    json.dump(hypotheses, json_file, indent=4)\n",
    "            except:\n",
    "                print(term)\n",
    "                print(i)\n",
    "\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
